{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7afb0928",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abe659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical computations\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder  # For scaling and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f3d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_pickle(obj, filename: str):\n",
    "    \"\"\"Dump an object to a pickle file.\"\"\"\n",
    "    with open(filename, 'wb') as f_out:\n",
    "        return pickle.dump(obj, f_out)\n",
    "\n",
    "def read_dataframe(filename: str):\n",
    "    \"\"\"Read a DataFrame from a csv.\"\"\"\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "def preprocess(df: pd.DataFrame, ss: StandardScaler, le: LabelEncoder):\n",
    "    \"\"\"Preprocess the DataFrame.\"\"\"\n",
    "    # Drop rows with missing values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "    # Encoding categorical features\n",
    "    categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "    for col in categorical_columns:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    # Scaling numerical features\n",
    "    numerical_columns = ['age', 'avg_glucose_level', 'bmi']\n",
    "    df[numerical_columns] = ss.fit_transform(df[numerical_columns])\n",
    "\n",
    "    return df, ss, le\n",
    "\n",
    "def run_data_prep(\n",
    "    input_file: str,\n",
    "    output_dir: str,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42\n",
    "):\n",
    "    \"\"\"Main function to run data preparation.\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Read the dataset\n",
    "    df = read_dataframe(input_file)\n",
    "\n",
    "    # Initialize StandardScaler and LabelEncoder\n",
    "    ss = StandardScaler()\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Preprocess the DataFrame\n",
    "    df, ss, le = preprocess(df, ss, le)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X = df.drop(columns=['stroke'])\n",
    "    y = df['stroke']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    # Save the preprocessed data\n",
    "    dump_pickle((X_train, y_train), os.path.join(output_dir, 'train.pkl'))\n",
    "    dump_pickle((X_test, y_test), os.path.join(output_dir, 'test.pkl'))\n",
    "    dump_pickle(ss, os.path.join(output_dir, 'scaler.pkl'))\n",
    "    dump_pickle(le, os.path.join(output_dir, 'label_encoder.pkl'))\n",
    "\n",
    "run_data_prep(input_file='./data/healthcare-dataset-stroke-data.csv', output_dir='./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db97137",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c7e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ecb9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://experiment-tracking:5000\")\n",
    "mlflow.set_experiment(\"random-forest-train\")\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    \"\"\"Load an object from a pickle file.\"\"\"\n",
    "    with open(filename, 'rb') as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "def run_train(data_path: str):\n",
    "    \"\"\"Main function to run training.\"\"\"\n",
    "    mlflow.sklearn.autolog()\n",
    "    # Load the preprocessed data\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, 'train.pkl'))\n",
    "    X_test, y_test = load_pickle(os.path.join(data_path, 'test.pkl'))\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Initialize the Random Forest Classifier\n",
    "        rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        # Train the model\n",
    "        rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "run_train(data_path='./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed61e00",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import mlflow\n",
    "import optuna\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dae110",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://experiment-tracking:5000\")\n",
    "mlflow.set_experiment(\"random-forest-hyperopt\")\n",
    "\n",
    "\n",
    "def load_pickle(filename: str):\n",
    "    \"\"\"Load an object from a pickle file.\"\"\"\n",
    "    with open(filename, 'rb') as f_in:\n",
    "        return pickle.load(f_in)\n",
    "\n",
    "def run_optimization(data_path: str, num_trials: int):\n",
    "    \"\"\"Main function to run hyperparameter optimization.\"\"\"\n",
    "    # Load the preprocessed data\n",
    "    X_train, y_train = load_pickle(os.path.join(data_path, 'train.pkl'))\n",
    "    X_test, y_test = load_pickle(os.path.join(data_path, 'test.pkl'))\n",
    "\n",
    "    # Disable autologging to avoid conflicts with Optuna\n",
    "    mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "    def objective(trial):\n",
    "        # Define the hyperparameters to tune\n",
    "        params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 10, 50, 1),\n",
    "                'max_depth': trial.suggest_int('max_depth', 1, 20, 1),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 10, 1),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4, 1),\n",
    "                'random_state': 42,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(params)\n",
    "            # Create the model with the suggested hyperparameters\n",
    "            rf = RandomForestClassifier(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_test)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        \n",
    "        return accuracy\n",
    "\n",
    "    # Create a study and optimize the objective function\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=num_trials)\n",
    "\n",
    "run_optimization(data_path='./models', num_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad122f95",
   "metadata": {},
   "source": [
    "# Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b58a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import ViewType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPO_EXPERIMENT_NAME = \"random-forest-hyperopt\"\n",
    "EXPERIMENT_NAME = \"random-forest-best-models\"\n",
    "RF_PARAMS = ['max_depth', 'n_estimators', 'min_samples_split', 'min_samples_leaf', 'random_state', 'n_jobs']\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://experiment-tracking:5000\")\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "def train_and_log_model(params):\n",
    "    # Load preprocessed training and validation data\n",
    "    X_train, y_train = load_pickle(os.path.join('./models', 'train.pkl'))\n",
    "    X_test, y_test = load_pickle(os.path.join('../models', 'test.pkl'))\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        for param in RF_PARAMS:\n",
    "            params[param] = int(params[param])\n",
    "\n",
    "        # Train the Random Forest Classifier\n",
    "        rf_classifier = RandomForestClassifier(**params)\n",
    "        rf_classifier.fit(X_train, y_train)\n",
    "        y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric('accuracy', accuracy)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(rf_classifier, artifact_path=\"model\")\n",
    "\n",
    "\n",
    "def run_register_model(data_path: str, top_n: int):\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Retrieve the top_n model runs and log the models\n",
    "    experiment = client.get_experiment_by_name(HPO_EXPERIMENT_NAME)\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=top_n,\n",
    "        order_by=[\"metrics.accuracy DESC\"]\n",
    "    )\n",
    "    for run in runs:\n",
    "        train_and_log_model(params=run.data.params)\n",
    "\n",
    "    # Select the model with the highest test accuracy\n",
    "    experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    best_run = client.search_runs(\n",
    "        experiment_ids=experiment.experiment_id,\n",
    "        run_view_type=ViewType.ACTIVE_ONLY,\n",
    "        max_results=top_n,\n",
    "        order_by=[\"metrics.accuracy DESC\"]\n",
    "    )[0]\n",
    "\n",
    "    # Register the best model\n",
    "    run_id = best_run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    mlflow.register_model(model_uri, name=\"rf-best-model\")\n",
    "\n",
    "\n",
    "run_register_model(\"./models/\", 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
